{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5277bb2c",
   "metadata": {
    "papermill": {
     "duration": 0.009335,
     "end_time": "2023-11-09T16:19:48.135003",
     "exception": false,
     "start_time": "2023-11-09T16:19:48.125668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hello Fellow Kagglers,\n",
    "\n",
    "This notebook demonstrates the training process of Mistral-7B using Low-Rank adaptation(LoRa) in bfloat16.\n",
    "\n",
    "The inference process is also in bfloat16 using cpu_offloading, making this the first end-to-end pipeline in bfloat16 for Mistral-7B.\n",
    "\n",
    "Additionally, the context window also doubles from 512â†’1024 compared to previous notebooks.\n",
    "\n",
    "I hope this notebook helps the community in tackling the hardware requirements for this competition, since Large-Language-Models are Large.\n",
    "\n",
    "Any feedback and ideas are welcome!\n",
    "\n",
    "**Inference**\n",
    "\n",
    "[Inference Notebook](https://www.kaggle.com/markwijkhuizen/daigt-mistral-7b-tpu-bfloat16-inference)\n",
    "\n",
    "These notebooks function as inspiration for this work, check them out (and consider to upvote them as well!)\n",
    "\n",
    "* [LLM detect AI comp Mistral-7B](https://www.kaggle.com/code/hotchpotch/train-llm-detect-ai-comp-mistral-7b/notebook)\n",
    "\n",
    "* [LLAMA 2 13B on TPU (Training)](https://www.kaggle.com/code/defdet/llama-2-13b-on-tpu-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dcf764a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:19:48.152045Z",
     "iopub.status.busy": "2023-11-09T16:19:48.151603Z",
     "iopub.status.idle": "2023-11-09T16:22:11.165170Z",
     "shell.execute_reply": "2023-11-09T16:22:11.164110Z"
    },
    "papermill": {
     "duration": 143.025327,
     "end_time": "2023-11-09T16:22:11.167888",
     "exception": false,
     "start_time": "2023-11-09T16:19:48.142561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchvision 0.15.1 requires torch==2.0.0, but you have torch 2.1.0+cpu which is incompatible.\r\n",
      "torchtext 0.15.1 requires torch==2.0.0, but you have torch 2.1.0+cpu which is incompatible.\r\n",
      "torchdata 0.6.0 requires torch==2.0.0, but you have torch 2.1.0+cpu which is incompatible.\r\n",
      "torchaudio 2.0.0 requires torch==2.0.0, but you have torch 2.1.0+cpu which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorboardx 2.6.1 requires protobuf>=4.22.3, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qq peft==0.6.0\n",
    "!pip install -qq bitsandbytes==0.41.1\n",
    "!pip install -qq accelerate==0.24.1\n",
    "!pip install -qq transformers==4.35.0\n",
    "!pip install -qq sentencepiece==0.1.99\n",
    "!pip install -qq nltk==3.8.1\n",
    "!pip install -qq torch~=2.1.0 --index-url https://download.pytorch.org/whl/cpu -q # Updating torch since we need the latest version\n",
    "!pip install -qq torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html -q\n",
    "!pip uninstall -qq tensorflow -y # If we don't do this, TF will take over TPU and cause permission error for PT\n",
    "!cp /kaggle/input/utils-xla/spmd_util.py . # From this repo: https://github.com/HeegyuKim/torch-xla-SPMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d99353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:11.185086Z",
     "iopub.status.busy": "2023-11-09T16:22:11.184781Z",
     "iopub.status.idle": "2023-11-09T16:22:26.944771Z",
     "shell.execute_reply": "2023-11-09T16:22:26.943904Z"
    },
    "papermill": {
     "duration": 15.771107,
     "end_time": "2023-11-09T16:22:26.946797",
     "exception": false,
     "start_time": "2023-11-09T16:22:11.175690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.1.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import sklearn\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "import torch_xla.debug.profiler as xp\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp # We also import mp modules if we wanna use that for some reason\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "\n",
    "import torch_xla.experimental.xla_sharding as xs\n",
    "import torch_xla.core.xla_model as xm\n",
    "from transformers import (\n",
    "    GPTNeoXConfig, T5Config, LlamaConfig, AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding, AutoConfig, AutoModelForSequenceClassification\n",
    ") # You can use any of models with those configs (even flan T5 xxl!). Other models are not supported.\n",
    "\n",
    "import torch_xla.runtime as xr\n",
    "\n",
    "xr.use_spmd()\n",
    "\n",
    "import torch_xla.experimental.xla_sharding as xs # \"experimental\" prefix always means you're gonna have a good time LMAO\n",
    "from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor\n",
    "from torch_xla.experimental.xla_sharding import Mesh\n",
    "from spmd_util import partition_module\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_colwidth = 99\n",
    "\n",
    "print(f'Torch Version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b52ffd",
   "metadata": {
    "papermill": {
     "duration": 0.007836,
     "end_time": "2023-11-09T16:22:26.963720",
     "exception": false,
     "start_time": "2023-11-09T16:22:26.955884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf37750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:26.981919Z",
     "iopub.status.busy": "2023-11-09T16:22:26.980723Z",
     "iopub.status.idle": "2023-11-09T16:22:26.986110Z",
     "shell.execute_reply": "2023-11-09T16:22:26.985406Z"
    },
    "papermill": {
     "duration": 0.0161,
     "end_time": "2023-11-09T16:22:26.987672",
     "exception": false,
     "start_time": "2023-11-09T16:22:26.971572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize TPU Device\n",
    "DEVICE = xm.xla_device()\n",
    "# Number Of Training Epochs\n",
    "NUM_EPOCHS = 1\n",
    "# Batch Size, should be evenly divisable by 8, since there are 8 TPU Nodes\n",
    "BATCH_SIZE = 16\n",
    "# Context Length of text in tokens, not words\n",
    "MAX_LENGTH = 1024\n",
    "# Number of Warmup Steps\n",
    "NUM_WARMUP_STEPS = 128\n",
    "# Maximum Learning RAte\n",
    "LR_MAX = 5e-5\n",
    "# Number of Labels, 1 sigmoid neuron with: 0=human, 1=AI\n",
    "NUM_LABELS = 1\n",
    "# We use the already famous Mistral-7B Model!\n",
    "TARGET_MODEL = 'mistralai/Mistral-7B-v0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a326ac3",
   "metadata": {
    "papermill": {
     "duration": 0.007618,
     "end_time": "2023-11-09T16:22:27.003344",
     "exception": false,
     "start_time": "2023-11-09T16:22:26.995726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e830a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:27.021602Z",
     "iopub.status.busy": "2023-11-09T16:22:27.021313Z",
     "iopub.status.idle": "2023-11-09T16:22:27.197843Z",
     "shell.execute_reply": "2023-11-09T16:22:27.197034Z"
    },
    "papermill": {
     "duration": 0.187916,
     "end_time": "2023-11-09T16:22:27.199826",
     "exception": false,
     "start_time": "2023-11-09T16:22:27.011910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/tokenizer.model',\n",
       " 'tokenizer/added_tokens.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huggingface Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/mistral-7b-v0-1/Mistral-7B-v0.1')\n",
    "# Set PAD token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# save tokenizer to load offline during inference\n",
    "tokenizer.save_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a74189d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:27.218919Z",
     "iopub.status.busy": "2023-11-09T16:22:27.218593Z",
     "iopub.status.idle": "2023-11-09T16:22:27.223237Z",
     "shell.execute_reply": "2023-11-09T16:22:27.222449Z"
    },
    "papermill": {
     "duration": 0.01646,
     "end_time": "2023-11-09T16:22:27.225135",
     "exception": false,
     "start_time": "2023-11-09T16:22:27.208675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility function giving token length\n",
    "def get_token_lengths(texts):\n",
    "    # tokenize and reaceive input_ids for reach text\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # return length of inputs_ids for each text\n",
    "    return [len(t) for t in input_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c97d6",
   "metadata": {
    "papermill": {
     "duration": 0.008523,
     "end_time": "2023-11-09T16:22:27.243729",
     "exception": false,
     "start_time": "2023-11-09T16:22:27.235206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfcaa94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:27.261701Z",
     "iopub.status.busy": "2023-11-09T16:22:27.261429Z",
     "iopub.status.idle": "2023-11-09T16:22:28.107062Z",
     "shell.execute_reply": "2023-11-09T16:22:28.106334Z"
    },
    "papermill": {
     "duration": 0.857374,
     "end_time": "2023-11-09T16:22:28.109688",
     "exception": false,
     "start_time": "2023-11-09T16:22:27.252314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To und...</td>\n",
       "      <td>0</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a one or any other motor vehicle to work? The stor...</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps one of the worlds greatest advancements and techno...</td>\n",
       "      <td>0</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id  \\\n",
       "0  0059830c          0   \n",
       "1  005db917          0   \n",
       "2  008f63e3          0   \n",
       "3  00940276          0   \n",
       "4  00c39458          0   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "0  Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and ...   \n",
       "1  Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, an...   \n",
       "2  \"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To und...   \n",
       "3  How often do you ride in a car? Do you drive a one or any other motor vehicle to work? The stor...   \n",
       "4  Cars are a wonderful thing. They are perhaps one of the worlds greatest advancements and techno...   \n",
       "\n",
       "   generated  token_count  \n",
       "0          0          750  \n",
       "1          0          618  \n",
       "2          0          936  \n",
       "3          0          892  \n",
       "4          0         1121  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1378 entries, 0 to 1377\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           1378 non-null   object\n",
      " 1   prompt_id    1378 non-null   int64 \n",
      " 2   text         1378 non-null   object\n",
      " 3   generated    1378 non-null   int64 \n",
      " 4   token_count  1378 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 54.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Competition training data which we will not use\n",
    "train_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\n",
    "\n",
    "# Add Text Length\n",
    "train_essays['token_count'] = get_token_lengths(train_essays['text'])\n",
    "\n",
    "# Display data\n",
    "display(train_essays.head())\n",
    "display(train_essays.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45503fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:28.127893Z",
     "iopub.status.busy": "2023-11-09T16:22:28.127613Z",
     "iopub.status.idle": "2023-11-09T16:22:28.135016Z",
     "shell.execute_reply": "2023-11-09T16:22:28.134314Z"
    },
    "papermill": {
     "duration": 0.018444,
     "end_time": "2023-11-09T16:22:28.136677",
     "exception": false,
     "start_time": "2023-11-09T16:22:28.118233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "generated       \n",
       "0           1375\n",
       "1              3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_essays['generated'].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0072194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:28.154450Z",
     "iopub.status.busy": "2023-11-09T16:22:28.154213Z",
     "iopub.status.idle": "2023-11-09T16:22:28.461569Z",
     "shell.execute_reply": "2023-11-09T16:22:28.460759Z"
    },
    "papermill": {
     "duration": 0.318535,
     "end_time": "2023-11-09T16:22:28.463409",
     "exception": false,
     "start_time": "2023-11-09T16:22:28.144874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token_count\n",
       "count         1378\n",
       "mean           713\n",
       "std            215\n",
       "min            278\n",
       "25%            570\n",
       "50%            671\n",
       "75%            813\n",
       "max           2420"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Token Count\n",
    "display(train_essays['token_count'].describe().to_frame().astype(int))\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.hist(train_essays['token_count'], bins=32)\n",
    "plt.xlim(0, plt.xlim()[1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539df3e",
   "metadata": {
    "papermill": {
     "duration": 0.008253,
     "end_time": "2023-11-09T16:22:28.480402",
     "exception": false,
     "start_time": "2023-11-09T16:22:28.472149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Proper Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7399e30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:28.499000Z",
     "iopub.status.busy": "2023-11-09T16:22:28.498713Z",
     "iopub.status.idle": "2023-11-09T16:22:42.360301Z",
     "shell.execute_reply": "2023-11-09T16:22:42.359580Z"
    },
    "papermill": {
     "duration": 13.873455,
     "end_time": "2023-11-09T16:22:42.362385",
     "exception": false,
     "start_time": "2023-11-09T16:22:28.488930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>fold</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E897534557AF</td>\n",
       "      <td>In recent years, technology has had a profound impact on our daily lives and the world around ...</td>\n",
       "      <td>1</td>\n",
       "      <td>mistral7binstruct_v2</td>\n",
       "      <td>\\nTask: Write an essay discussing the positive impact of technology and how it makes humans bei...</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFBA34FFE11D</td>\n",
       "      <td>Should students participate in an extracurricular activity? It may seem like a simple question,...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af37ecf5</td>\n",
       "      <td>The electoral college is a symbol of mockery and deprivation of our rights. Voting using this s...</td>\n",
       "      <td>0</td>\n",
       "      <td>train_essays</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5EC2696BAD78</td>\n",
       "      <td>This is why I think the principle should allow students to bring phones to school and use them ...</td>\n",
       "      <td>0</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama_70b_v1843</td>\n",
       "      <td>I strongly believe that meditation and mindfulness practices should be included in schools. The...</td>\n",
       "      <td>1</td>\n",
       "      <td>llama_70b_v1</td>\n",
       "      <td>Some schools have implemented meditation and mindfulness practices into the school day. Write a...</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          essay_id  \\\n",
       "0     E897534557AF   \n",
       "1     DFBA34FFE11D   \n",
       "2         af37ecf5   \n",
       "3     5EC2696BAD78   \n",
       "4  llama_70b_v1843   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "0   In recent years, technology has had a profound impact on our daily lives and the world around ...   \n",
       "1  Should students participate in an extracurricular activity? It may seem like a simple question,...   \n",
       "2  The electoral college is a symbol of mockery and deprivation of our rights. Voting using this s...   \n",
       "3  This is why I think the principle should allow students to bring phones to school and use them ...   \n",
       "4  I strongly believe that meditation and mindfulness practices should be included in schools. The...   \n",
       "\n",
       "   label                source  \\\n",
       "0      1  mistral7binstruct_v2   \n",
       "1      0       persuade_corpus   \n",
       "2      0          train_essays   \n",
       "3      0       persuade_corpus   \n",
       "4      1          llama_70b_v1   \n",
       "\n",
       "                                                                                               prompt  \\\n",
       "0  \\nTask: Write an essay discussing the positive impact of technology and how it makes humans bei...   \n",
       "1                                                                                                 NaN   \n",
       "2                                                                                                 NaN   \n",
       "3                                                                                                 NaN   \n",
       "4  Some schools have implemented meditation and mindfulness practices into the school day. Write a...   \n",
       "\n",
       "   fold  token_count  \n",
       "0     1          315  \n",
       "1     2          791  \n",
       "2     5          703  \n",
       "3     8          232  \n",
       "4     0          424  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44206 entries, 0 to 44205\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   essay_id     44206 non-null  object\n",
      " 1   text         44206 non-null  object\n",
      " 2   label        44206 non-null  int64 \n",
      " 3   source       44206 non-null  object\n",
      " 4   prompt       12911 non-null  object\n",
      " 5   fold         44206 non-null  int64 \n",
      " 6   token_count  44206 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the widely used \"proper_train_dataset\"\n",
    "proper_train_dataset = pd.read_csv('/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv')\n",
    "\n",
    "# Add Text Length\n",
    "proper_train_dataset['token_count'] = get_token_lengths(proper_train_dataset['text'])\n",
    "\n",
    "display(proper_train_dataset.head())\n",
    "display(proper_train_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460a7b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:42.384131Z",
     "iopub.status.busy": "2023-11-09T16:22:42.383806Z",
     "iopub.status.idle": "2023-11-09T16:22:42.569599Z",
     "shell.execute_reply": "2023-11-09T16:22:42.568776Z"
    },
    "papermill": {
     "duration": 0.198621,
     "end_time": "2023-11-09T16:22:42.571504",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.372883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token_count\n",
       "count        44206\n",
       "mean           484\n",
       "std            220\n",
       "min             65\n",
       "25%            341\n",
       "50%            449\n",
       "75%            573\n",
       "max           9293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Word Count\n",
    "display(proper_train_dataset['token_count'].describe().to_frame().astype(int))\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.hist(proper_train_dataset['token_count'], bins=32)\n",
    "plt.xlim(0, plt.xlim()[1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f72d5",
   "metadata": {
    "papermill": {
     "duration": 0.009551,
     "end_time": "2023-11-09T16:22:42.591020",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.581469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sample Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee43248e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:42.610945Z",
     "iopub.status.busy": "2023-11-09T16:22:42.610689Z",
     "iopub.status.idle": "2023-11-09T16:22:42.626622Z",
     "shell.execute_reply": "2023-11-09T16:22:42.625998Z"
    },
    "papermill": {
     "duration": 0.028023,
     "end_time": "2023-11-09T16:22:42.628324",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.600301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa        0.1\n",
       "1  1111bbbb        0.9\n",
       "2  2222cccc        0.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n",
    "\n",
    "display(sample_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f0d6e5",
   "metadata": {
    "papermill": {
     "duration": 0.009309,
     "end_time": "2023-11-09T16:22:42.646938",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.637629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f3cd59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:42.667024Z",
     "iopub.status.busy": "2023-11-09T16:22:42.666779Z",
     "iopub.status.idle": "2023-11-09T16:22:42.687939Z",
     "shell.execute_reply": "2023-11-09T16:22:42.687280Z"
    },
    "papermill": {
     "duration": 0.033378,
     "end_time": "2023-11-09T16:22:42.689595",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.656217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44206 entries, 0 to 44205\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    44206 non-null  object\n",
      " 1   label   44206 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 690.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count\n",
       "label       \n",
       "0      29792\n",
       "1      14414"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Label Columns\n",
    "LABEL = 'label'\n",
    "# Columns to Use\n",
    "columns = ['text', LABEL]\n",
    "# Acquire Training DataFrame\n",
    "df = proper_train_dataset[columns]\n",
    "\n",
    "display(df.info())\n",
    "# Label Counts\n",
    "display(df[LABEL].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f0d8e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:42.710221Z",
     "iopub.status.busy": "2023-11-09T16:22:42.709987Z",
     "iopub.status.idle": "2023-11-09T16:22:42.713907Z",
     "shell.execute_reply": "2023-11-09T16:22:42.713189Z"
    },
    "papermill": {
     "duration": 0.016535,
     "end_time": "2023-11-09T16:22:42.715722",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.699187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 44206\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = len(df)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2a532",
   "metadata": {
    "papermill": {
     "duration": 0.009779,
     "end_time": "2023-11-09T16:22:42.735205",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.725426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenize Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93bf4c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:42.755698Z",
     "iopub.status.busy": "2023-11-09T16:22:42.755473Z",
     "iopub.status.idle": "2023-11-09T16:22:57.386946Z",
     "shell.execute_reply": "2023-11-09T16:22:57.386160Z"
    },
    "papermill": {
     "duration": 14.64406,
     "end_time": "2023-11-09T16:22:57.388885",
     "exception": false,
     "start_time": "2023-11-09T16:22:42.744825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_IDS shape: (44206, 1024), ATTENTION_MASKS shape: (44206, 1024)\n",
      "GENERATED shape: (44206, 1)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Data\n",
    "tokens = tokenizer(\n",
    "    df['text'].tolist(), # Texts\n",
    "    padding='max_length', # Pad texts to maximum length\n",
    "    max_length=MAX_LENGTH, # Maximum token length\n",
    "    truncation=True, # Truncate texts if they are too long\n",
    "    return_tensors='np', # Return Numpy array\n",
    ")\n",
    "\n",
    "# Input IDs are the token IDs\n",
    "INPUT_IDS = tokens['input_ids']\n",
    "# Attention Masks to Ignore Padding Tokens\n",
    "ATTENTION_MASKS = tokens['attention_mask']\n",
    "# Generated By AI Label of Texts\n",
    "GENERATED = df[LABEL].values.reshape(-1,1).astype(np.float32)\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')\n",
    "print(f'GENERATED shape: {GENERATED.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663cd51",
   "metadata": {
    "papermill": {
     "duration": 0.009651,
     "end_time": "2023-11-09T16:22:57.408753",
     "exception": false,
     "start_time": "2023-11-09T16:22:57.399102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3c942a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:22:57.429094Z",
     "iopub.status.busy": "2023-11-09T16:22:57.428810Z",
     "iopub.status.idle": "2023-11-09T16:26:10.896771Z",
     "shell.execute_reply": "2023-11-09T16:26:10.896089Z"
    },
    "papermill": {
     "duration": 193.486645,
     "end_time": "2023-11-09T16:26:10.904882",
     "exception": false,
     "start_time": "2023-11-09T16:22:57.418237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [02:00<00:00, 60.45s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/mistral-7b-v0-1/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BigBird model for classification with 1 target label\n",
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    '/kaggle/input/mistral-7b-v0-1/Mistral-7B-v0.1',\n",
    "    num_labels=NUM_LABELS,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "# No idea why this is needed\n",
    "base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "# Assign Padding TOKEN\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca72f96",
   "metadata": {
    "papermill": {
     "duration": 0.009899,
     "end_time": "2023-11-09T16:26:10.925011",
     "exception": false,
     "start_time": "2023-11-09T16:26:10.915112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Low-Rank Adaptation\n",
    "\n",
    "Baed on this paper: [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8cde10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:10.946526Z",
     "iopub.status.busy": "2023-11-09T16:26:10.946260Z",
     "iopub.status.idle": "2023-11-09T16:26:10.950509Z",
     "shell.execute_reply": "2023-11-09T16:26:10.949739Z"
    },
    "papermill": {
     "duration": 0.017152,
     "end_time": "2023-11-09T16:26:10.952253",
     "exception": false,
     "start_time": "2023-11-09T16:26:10.935101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LoRa\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_dropout=0.10,\n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    # Only Use Output and Values Projection\n",
    "    target_modules=[\n",
    "        'o_proj',\n",
    "        'v_proj',\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd92fc4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:10.973531Z",
     "iopub.status.busy": "2023-11-09T16:26:10.973298Z",
     "iopub.status.idle": "2023-11-09T16:26:11.128064Z",
     "shell.execute_reply": "2023-11-09T16:26:11.127143Z"
    },
    "papermill": {
     "duration": 0.168559,
     "end_time": "2023-11-09T16:26:11.130778",
     "exception": false,
     "start_time": "2023-11-09T16:26:10.962219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create LoRa Model\n",
    "model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aec02944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:11.153771Z",
     "iopub.status.busy": "2023-11-09T16:26:11.153473Z",
     "iopub.status.idle": "2023-11-09T16:26:11.160518Z",
     "shell.execute_reply": "2023-11-09T16:26:11.159525Z"
    },
    "papermill": {
     "duration": 0.020972,
     "end_time": "2023-11-09T16:26:11.162922",
     "exception": false,
     "start_time": "2023-11-09T16:26:11.141950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,819,840 || all params: 7,117,484,032 || trainable%: 0.09581812855972979\n"
     ]
    }
   ],
   "source": [
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d23ffe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:11.184538Z",
     "iopub.status.busy": "2023-11-09T16:26:11.184302Z",
     "iopub.status.idle": "2023-11-09T16:26:11.213708Z",
     "shell.execute_reply": "2023-11-09T16:26:11.212903Z"
    },
    "papermill": {
     "duration": 0.0436,
     "end_time": "2023-11-09T16:26:11.216887",
     "exception": false,
     "start_time": "2023-11-09T16:26:11.173287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#param</th>\n",
       "      <th>name</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>16384</td>\n",
       "      <td>base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>65536</td>\n",
       "      <td>base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>4096</td>\n",
       "      <td>base_model.model.score.modules_to_save.default.weight</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #param  \\\n",
       "0     65536   \n",
       "1     16384   \n",
       "2     65536   \n",
       "3     65536   \n",
       "4     65536   \n",
       "5     16384   \n",
       "6     65536   \n",
       "7     65536   \n",
       "8     65536   \n",
       "9     16384   \n",
       "10    65536   \n",
       "11    65536   \n",
       "12    65536   \n",
       "13    16384   \n",
       "14    65536   \n",
       "15    65536   \n",
       "16    65536   \n",
       "17    16384   \n",
       "18    65536   \n",
       "19    65536   \n",
       "20    65536   \n",
       "21    16384   \n",
       "22    65536   \n",
       "23    65536   \n",
       "24    65536   \n",
       "25    16384   \n",
       "26    65536   \n",
       "27    65536   \n",
       "28    65536   \n",
       "29    16384   \n",
       "30    65536   \n",
       "31    65536   \n",
       "32    65536   \n",
       "33    16384   \n",
       "34    65536   \n",
       "35    65536   \n",
       "36    65536   \n",
       "37    16384   \n",
       "38    65536   \n",
       "39    65536   \n",
       "40    65536   \n",
       "41    16384   \n",
       "42    65536   \n",
       "43    65536   \n",
       "44    65536   \n",
       "45    16384   \n",
       "46    65536   \n",
       "47    65536   \n",
       "48    65536   \n",
       "49    16384   \n",
       "50    65536   \n",
       "51    65536   \n",
       "52    65536   \n",
       "53    16384   \n",
       "54    65536   \n",
       "55    65536   \n",
       "56    65536   \n",
       "57    16384   \n",
       "58    65536   \n",
       "59    65536   \n",
       "60    65536   \n",
       "61    16384   \n",
       "62    65536   \n",
       "63    65536   \n",
       "64    65536   \n",
       "65    16384   \n",
       "66    65536   \n",
       "67    65536   \n",
       "68    65536   \n",
       "69    16384   \n",
       "70    65536   \n",
       "71    65536   \n",
       "72    65536   \n",
       "73    16384   \n",
       "74    65536   \n",
       "75    65536   \n",
       "76    65536   \n",
       "77    16384   \n",
       "78    65536   \n",
       "79    65536   \n",
       "80    65536   \n",
       "81    16384   \n",
       "82    65536   \n",
       "83    65536   \n",
       "84    65536   \n",
       "85    16384   \n",
       "86    65536   \n",
       "87    65536   \n",
       "88    65536   \n",
       "89    16384   \n",
       "90    65536   \n",
       "91    65536   \n",
       "92    65536   \n",
       "93    16384   \n",
       "94    65536   \n",
       "95    65536   \n",
       "96    65536   \n",
       "97    16384   \n",
       "98    65536   \n",
       "99    65536   \n",
       "100   65536   \n",
       "101   16384   \n",
       "102   65536   \n",
       "103   65536   \n",
       "104   65536   \n",
       "105   16384   \n",
       "106   65536   \n",
       "107   65536   \n",
       "108   65536   \n",
       "109   16384   \n",
       "110   65536   \n",
       "111   65536   \n",
       "112   65536   \n",
       "113   16384   \n",
       "114   65536   \n",
       "115   65536   \n",
       "116   65536   \n",
       "117   16384   \n",
       "118   65536   \n",
       "119   65536   \n",
       "120   65536   \n",
       "121   16384   \n",
       "122   65536   \n",
       "123   65536   \n",
       "124   65536   \n",
       "125   16384   \n",
       "126   65536   \n",
       "127   65536   \n",
       "128    4096   \n",
       "\n",
       "                                                                        name  \\\n",
       "0     base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight   \n",
       "1     base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight   \n",
       "2     base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight   \n",
       "3     base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight   \n",
       "4     base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight   \n",
       "5     base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight   \n",
       "6     base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight   \n",
       "7     base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight   \n",
       "8     base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight   \n",
       "9     base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight   \n",
       "10    base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight   \n",
       "11    base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight   \n",
       "12    base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight   \n",
       "13    base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight   \n",
       "14    base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight   \n",
       "15    base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight   \n",
       "16    base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight   \n",
       "17    base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight   \n",
       "18    base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight   \n",
       "19    base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight   \n",
       "20    base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight   \n",
       "21    base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight   \n",
       "22    base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight   \n",
       "23    base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight   \n",
       "24    base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight   \n",
       "25    base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight   \n",
       "26    base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight   \n",
       "27    base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight   \n",
       "28    base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight   \n",
       "29    base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight   \n",
       "30    base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight   \n",
       "31    base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight   \n",
       "32    base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight   \n",
       "33    base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight   \n",
       "34    base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight   \n",
       "35    base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight   \n",
       "36    base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight   \n",
       "37    base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight   \n",
       "38    base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight   \n",
       "39    base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight   \n",
       "40   base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight   \n",
       "41   base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight   \n",
       "42   base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight   \n",
       "43   base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight   \n",
       "44   base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight   \n",
       "45   base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight   \n",
       "46   base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight   \n",
       "47   base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight   \n",
       "48   base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight   \n",
       "49   base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight   \n",
       "50   base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight   \n",
       "51   base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight   \n",
       "52   base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight   \n",
       "53   base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight   \n",
       "54   base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight   \n",
       "55   base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight   \n",
       "56   base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight   \n",
       "57   base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight   \n",
       "58   base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight   \n",
       "59   base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight   \n",
       "60   base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight   \n",
       "61   base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight   \n",
       "62   base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight   \n",
       "63   base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight   \n",
       "64   base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight   \n",
       "65   base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight   \n",
       "66   base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight   \n",
       "67   base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight   \n",
       "68   base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight   \n",
       "69   base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight   \n",
       "70   base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight   \n",
       "71   base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight   \n",
       "72   base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight   \n",
       "73   base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight   \n",
       "74   base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight   \n",
       "75   base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight   \n",
       "76   base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight   \n",
       "77   base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight   \n",
       "78   base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight   \n",
       "79   base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight   \n",
       "80   base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight   \n",
       "81   base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight   \n",
       "82   base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight   \n",
       "83   base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight   \n",
       "84   base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight   \n",
       "85   base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight   \n",
       "86   base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight   \n",
       "87   base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight   \n",
       "88   base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight   \n",
       "89   base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight   \n",
       "90   base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight   \n",
       "91   base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight   \n",
       "92   base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight   \n",
       "93   base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight   \n",
       "94   base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight   \n",
       "95   base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight   \n",
       "96   base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight   \n",
       "97   base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight   \n",
       "98   base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight   \n",
       "99   base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight   \n",
       "100  base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight   \n",
       "101  base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight   \n",
       "102  base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight   \n",
       "103  base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight   \n",
       "104  base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight   \n",
       "105  base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight   \n",
       "106  base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight   \n",
       "107  base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight   \n",
       "108  base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight   \n",
       "109  base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight   \n",
       "110  base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight   \n",
       "111  base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight   \n",
       "112  base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight   \n",
       "113  base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight   \n",
       "114  base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight   \n",
       "115  base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight   \n",
       "116  base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight   \n",
       "117  base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight   \n",
       "118  base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight   \n",
       "119  base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight   \n",
       "120  base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight   \n",
       "121  base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight   \n",
       "122  base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight   \n",
       "123  base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight   \n",
       "124  base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight   \n",
       "125  base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight   \n",
       "126  base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight   \n",
       "127  base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight   \n",
       "128                    base_model.model.score.modules_to_save.default.weight   \n",
       "\n",
       "              dtype  \n",
       "0     torch.float32  \n",
       "1     torch.float32  \n",
       "2     torch.float32  \n",
       "3     torch.float32  \n",
       "4     torch.float32  \n",
       "5     torch.float32  \n",
       "6     torch.float32  \n",
       "7     torch.float32  \n",
       "8     torch.float32  \n",
       "9     torch.float32  \n",
       "10    torch.float32  \n",
       "11    torch.float32  \n",
       "12    torch.float32  \n",
       "13    torch.float32  \n",
       "14    torch.float32  \n",
       "15    torch.float32  \n",
       "16    torch.float32  \n",
       "17    torch.float32  \n",
       "18    torch.float32  \n",
       "19    torch.float32  \n",
       "20    torch.float32  \n",
       "21    torch.float32  \n",
       "22    torch.float32  \n",
       "23    torch.float32  \n",
       "24    torch.float32  \n",
       "25    torch.float32  \n",
       "26    torch.float32  \n",
       "27    torch.float32  \n",
       "28    torch.float32  \n",
       "29    torch.float32  \n",
       "30    torch.float32  \n",
       "31    torch.float32  \n",
       "32    torch.float32  \n",
       "33    torch.float32  \n",
       "34    torch.float32  \n",
       "35    torch.float32  \n",
       "36    torch.float32  \n",
       "37    torch.float32  \n",
       "38    torch.float32  \n",
       "39    torch.float32  \n",
       "40    torch.float32  \n",
       "41    torch.float32  \n",
       "42    torch.float32  \n",
       "43    torch.float32  \n",
       "44    torch.float32  \n",
       "45    torch.float32  \n",
       "46    torch.float32  \n",
       "47    torch.float32  \n",
       "48    torch.float32  \n",
       "49    torch.float32  \n",
       "50    torch.float32  \n",
       "51    torch.float32  \n",
       "52    torch.float32  \n",
       "53    torch.float32  \n",
       "54    torch.float32  \n",
       "55    torch.float32  \n",
       "56    torch.float32  \n",
       "57    torch.float32  \n",
       "58    torch.float32  \n",
       "59    torch.float32  \n",
       "60    torch.float32  \n",
       "61    torch.float32  \n",
       "62    torch.float32  \n",
       "63    torch.float32  \n",
       "64    torch.float32  \n",
       "65    torch.float32  \n",
       "66    torch.float32  \n",
       "67    torch.float32  \n",
       "68    torch.float32  \n",
       "69    torch.float32  \n",
       "70    torch.float32  \n",
       "71    torch.float32  \n",
       "72    torch.float32  \n",
       "73    torch.float32  \n",
       "74    torch.float32  \n",
       "75    torch.float32  \n",
       "76    torch.float32  \n",
       "77    torch.float32  \n",
       "78    torch.float32  \n",
       "79    torch.float32  \n",
       "80    torch.float32  \n",
       "81    torch.float32  \n",
       "82    torch.float32  \n",
       "83    torch.float32  \n",
       "84    torch.float32  \n",
       "85    torch.float32  \n",
       "86    torch.float32  \n",
       "87    torch.float32  \n",
       "88    torch.float32  \n",
       "89    torch.float32  \n",
       "90    torch.float32  \n",
       "91    torch.float32  \n",
       "92    torch.float32  \n",
       "93    torch.float32  \n",
       "94    torch.float32  \n",
       "95    torch.float32  \n",
       "96    torch.float32  \n",
       "97    torch.float32  \n",
       "98    torch.float32  \n",
       "99    torch.float32  \n",
       "100   torch.float32  \n",
       "101   torch.float32  \n",
       "102   torch.float32  \n",
       "103   torch.float32  \n",
       "104   torch.float32  \n",
       "105   torch.float32  \n",
       "106   torch.float32  \n",
       "107   torch.float32  \n",
       "108   torch.float32  \n",
       "109   torch.float32  \n",
       "110   torch.float32  \n",
       "111   torch.float32  \n",
       "112   torch.float32  \n",
       "113   torch.float32  \n",
       "114   torch.float32  \n",
       "115   torch.float32  \n",
       "116   torch.float32  \n",
       "117   torch.float32  \n",
       "118   torch.float32  \n",
       "119   torch.float32  \n",
       "120   torch.float32  \n",
       "121   torch.float32  \n",
       "122   torch.float32  \n",
       "123   torch.float32  \n",
       "124   torch.float32  \n",
       "125   torch.float32  \n",
       "126   torch.float32  \n",
       "127   torch.float32  \n",
       "128  torch.bfloat16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "N_TRAINABLE_PARAMS: 6,819,840\n",
      "N_TRAINABLE_LAYERS: 129\n",
      "===============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verfy The Trainable Layers\n",
    "MODEL_LAYERS_ROWS = []\n",
    "TRAINABLE_PARAMS = []\n",
    "N_TRAINABLE_PARAMS = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # Layer Parameter Count\n",
    "    n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
    "    # Only Trainable Layers\n",
    "    if param.requires_grad:\n",
    "        # Add Layer Information\n",
    "        MODEL_LAYERS_ROWS.append({\n",
    "            '#param': n_parameters,\n",
    "            'name': name,\n",
    "            'dtype': param.data.dtype,\n",
    "        })\n",
    "        # Append Trainable Parameter\n",
    "        TRAINABLE_PARAMS.append({ 'params': param })\n",
    "        # Add Number Of Trainable Parameters\"\n",
    "        N_TRAINABLE_PARAMS += n_parameters\n",
    "        \n",
    "display(pd.DataFrame(MODEL_LAYERS_ROWS))\n",
    "\n",
    "print(f\"\"\"\n",
    "===============================\n",
    "N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}\n",
    "N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}\n",
    "===============================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b222f9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:11.242625Z",
     "iopub.status.busy": "2023-11-09T16:26:11.242394Z",
     "iopub.status.idle": "2023-11-09T16:26:30.805906Z",
     "shell.execute_reply": "2023-11-09T16:26:30.804906Z"
    },
    "papermill": {
     "duration": 19.578575,
     "end_time": "2023-11-09T16:26:30.807862",
     "exception": false,
     "start_time": "2023-11-09T16:26:11.229287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_devices: 8\n"
     ]
    }
   ],
   "source": [
    "# Number of TPU Nodes\n",
    "num_devices = xr.global_runtime_device_count()\n",
    "mesh_shape = (1, num_devices, 1)\n",
    "device_ids = np.array(range(num_devices))\n",
    "mesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))\n",
    "partition_module(model, mesh)\n",
    "\n",
    "print(f'num_devices: {num_devices}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f7d74",
   "metadata": {
    "papermill": {
     "duration": 0.011111,
     "end_time": "2023-11-09T16:26:30.830800",
     "exception": false,
     "start_time": "2023-11-09T16:26:30.819689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Learning Rate & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f46a75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:30.855277Z",
     "iopub.status.busy": "2023-11-09T16:26:30.854991Z",
     "iopub.status.idle": "2023-11-09T16:26:30.863871Z",
     "shell.execute_reply": "2023-11-09T16:26:30.862989Z"
    },
    "papermill": {
     "duration": 0.023038,
     "end_time": "2023-11-09T16:26:30.865499",
     "exception": false,
     "start_time": "2023-11-09T16:26:30.842461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE: 16, N_SAMPLES: 44206, STEPS_PER_EPOCH: 2762\n"
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPOCH = N_SAMPLES // BATCH_SIZE\n",
    "\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(), lr=LR_MAX)\n",
    "# Cosine Learning Rate With Warmup\n",
    "lr_scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "    optimizer=OPTIMIZER,\n",
    "    num_warmup_steps=NUM_WARMUP_STEPS,\n",
    "    num_training_steps=STEPS_PER_EPOCH * NUM_EPOCHS,\n",
    ")\n",
    "\n",
    "\n",
    "print(f'BATCH_SIZE: {BATCH_SIZE}, N_SAMPLES: {N_SAMPLES}, STEPS_PER_EPOCH: {STEPS_PER_EPOCH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff45593e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:30.889152Z",
     "iopub.status.busy": "2023-11-09T16:26:30.888920Z",
     "iopub.status.idle": "2023-11-09T16:26:30.893564Z",
     "shell.execute_reply": "2023-11-09T16:26:30.892730Z"
    },
    "papermill": {
     "duration": 0.018575,
     "end_time": "2023-11-09T16:26:30.895241",
     "exception": false,
     "start_time": "2023-11-09T16:26:30.876666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the data type for the optimizer's state (e.g., momentum buffers)\n",
    "for state in OPTIMIZER.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:\n",
    "            state[v] = v.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e88dc7",
   "metadata": {
    "papermill": {
     "duration": 0.011105,
     "end_time": "2023-11-09T16:26:30.917491",
     "exception": false,
     "start_time": "2023-11-09T16:26:30.906386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95f3cb31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:30.941095Z",
     "iopub.status.busy": "2023-11-09T16:26:30.940855Z",
     "iopub.status.idle": "2023-11-09T16:26:30.947365Z",
     "shell.execute_reply": "2023-11-09T16:26:30.946267Z"
    },
    "papermill": {
     "duration": 0.020423,
     "end_time": "2023-11-09T16:26:30.949061",
     "exception": false,
     "start_time": "2023-11-09T16:26:30.928638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#POS_IDXS: 14414, #NEG_IDXS: 29792\n"
     ]
    }
   ],
   "source": [
    "POS_IDXS = np.argwhere(df[LABEL] == 1).squeeze()\n",
    "NEG_IDXS = np.argwhere(df[LABEL] == 0).squeeze()\n",
    "\n",
    "print(f'#POS_IDXS: {POS_IDXS.size}, #NEG_IDXS: {NEG_IDXS.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "580c454a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:30.972797Z",
     "iopub.status.busy": "2023-11-09T16:26:30.972531Z",
     "iopub.status.idle": "2023-11-09T16:26:30.978619Z",
     "shell.execute_reply": "2023-11-09T16:26:30.977873Z"
    },
    "papermill": {
     "duration": 0.020155,
     "end_time": "2023-11-09T16:26:30.980390",
     "exception": false,
     "start_time": "2023-11-09T16:26:30.960235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_dataset(batch_size):\n",
    "    IDXS = np.arange(N_SAMPLES-(N_SAMPLES%batch_size))\n",
    "    while True:\n",
    "        # Shuffle Indices\n",
    "        np.random.shuffle(IDXS)\n",
    "        # Iterate Over All Indices Once\n",
    "        for idxs in IDXS.reshape(-1,batch_size):\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)\n",
    "            labels = torch.tensor(GENERATED[idxs]).to(DEVICE)\n",
    "            # Shard Over TPU Nodes\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))\n",
    "\n",
    "            yield input_ids, attention_mask, labels\n",
    "        \n",
    "TRAIN_DATASET = train_dataset(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "426f8c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:31.004751Z",
     "iopub.status.busy": "2023-11-09T16:26:31.004502Z",
     "iopub.status.idle": "2023-11-09T16:26:31.014060Z",
     "shell.execute_reply": "2023-11-09T16:26:31.013026Z"
    },
    "papermill": {
     "duration": 0.024082,
     "end_time": "2023-11-09T16:26:31.015821",
     "exception": false,
     "start_time": "2023-11-09T16:26:30.991739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([16, 1024]), dtype: torch.int64\n",
      "attention_mask shape: torch.Size([16, 1024]), dtype: torch.int64\n",
      "labels shape: torch.Size([16, 1]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "\n",
    "print(f'input_ids shape: {input_ids.shape}, dtype: {input_ids.dtype}')\n",
    "print(f'attention_mask shape: {attention_mask.shape}, dtype: {attention_mask.dtype}')\n",
    "print(f'labels shape: {labels.shape}, dtype: {labels.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8164e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:26:31.040011Z",
     "iopub.status.busy": "2023-11-09T16:26:31.039757Z",
     "iopub.status.idle": "2023-11-09T16:26:59.965693Z",
     "shell.execute_reply": "2023-11-09T16:26:59.964590Z"
    },
    "papermill": {
     "duration": 28.940297,
     "end_time": "2023-11-09T16:26:59.967715",
     "exception": false,
     "start_time": "2023-11-09T16:26:31.027418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[-12.2500],\n",
      "        [ -7.7812],\n",
      "        [-14.3750],\n",
      "        [  3.8125],\n",
      "        [-11.0000],\n",
      "        [-12.5000],\n",
      "        [ -3.0625],\n",
      "        [ -9.8750],\n",
      "        [  3.7031],\n",
      "        [ -4.2812],\n",
      "        [ -4.5312],\n",
      "        [  0.6875],\n",
      "        [  4.7500],\n",
      "        [ -1.1875],\n",
      "        [ -0.9258],\n",
      "        [ -3.8594]], device='xla:0', dtype=torch.bfloat16), dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# Dummy Prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "print(f'logits: {outputs.logits}, dtype: {outputs.logits.dtype}')\n",
    "# print(f'loss: {outputs.loss}, dtype: {outputs.loss.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3280119",
   "metadata": {
    "papermill": {
     "duration": 0.011845,
     "end_time": "2023-11-09T16:26:59.991555",
     "exception": false,
     "start_time": "2023-11-09T16:26:59.979710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "558e80db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:27:00.016349Z",
     "iopub.status.busy": "2023-11-09T16:27:00.016041Z",
     "iopub.status.idle": "2023-11-09T16:27:00.024751Z",
     "shell.execute_reply": "2023-11-09T16:27:00.023782Z"
    },
    "papermill": {
     "duration": 0.023793,
     "end_time": "2023-11-09T16:27:00.026900",
     "exception": false,
     "start_time": "2023-11-09T16:27:00.003107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put Model In Train Modus\n",
    "model.train()\n",
    "\n",
    "# Loss Function, basic Binary Cross Entropy\n",
    "LOSS_FN = torch.nn.BCEWithLogitsLoss().to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ed2a84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T16:27:00.051269Z",
     "iopub.status.busy": "2023-11-09T16:27:00.050950Z",
     "iopub.status.idle": "2023-11-09T19:14:57.297032Z",
     "shell.execute_reply": "2023-11-09T19:14:57.296021Z"
    },
    "papermill": {
     "duration": 10077.261617,
     "end_time": "2023-11-09T19:14:57.299990",
     "exception": false,
     "start_time": "2023-11-09T16:27:00.038373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 01/01 | 2761/2762 lr: 1.78E-11, Âµ_loss: 0.034, step_loss: 0.001, Âµ_auc: 0.999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [2:47:57<00:00, 10077.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 01/01 | 2762/2762 lr: 0.00E+00, Âµ_loss: 0.034, step_loss: 0.000, Âµ_auc: 0.999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    METRICS = {\n",
    "        'loss': [],\n",
    "        'auc': {\n",
    "            'y_true': [],\n",
    "            'y_pred': [],\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        # Zero Out Gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "        # Get Batch\n",
    "        input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "        # Forward Pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Logits Float32\n",
    "        logits = outputs.logits.to(dtype=torch.float32)\n",
    "        # Backward Pass\n",
    "        loss = LOSS_FN(logits, labels)\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        OPTIMIZER.step()\n",
    "        xm.mark_step()\n",
    "        # Update Learning Rate Scheduler\n",
    "        lr_scheduler.step()\n",
    "        # Update Metrics And Progress Bar\n",
    "        METRICS['loss'].append(float(loss))\n",
    "        METRICS['auc']['y_true'] += labels.squeeze().tolist()\n",
    "        METRICS['auc']['y_pred'] += logits.sigmoid().tolist()\n",
    "        # Metrics Shown After Both Classes Present\n",
    "        if np.unique(METRICS['auc']['y_true']).size == 2:\n",
    "            metrics = 'Âµ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n",
    "            metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])\n",
    "            metrics += ', Âµ_auc: {:.3f}'.format(\n",
    "                sklearn.metrics.roc_auc_score(METRICS['auc']['y_true'], METRICS['auc']['y_pred'])\n",
    "            )\n",
    "\n",
    "            lr = OPTIMIZER.param_groups[0]['lr']\n",
    "            print('\\r'*100, f'{epoch+1:02}/{NUM_EPOCHS:02} | {step+1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509e5e8",
   "metadata": {
    "papermill": {
     "duration": 0.338329,
     "end_time": "2023-11-09T19:14:57.969276",
     "exception": false,
     "start_time": "2023-11-09T19:14:57.630947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aa69f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T19:14:58.625302Z",
     "iopub.status.busy": "2023-11-09T19:14:58.624929Z",
     "iopub.status.idle": "2023-11-09T19:16:42.467557Z",
     "shell.execute_reply": "2023-11-09T19:16:42.466541Z"
    },
    "papermill": {
     "duration": 104.180399,
     "end_time": "2023-11-09T19:16:42.470297",
     "exception": false,
     "start_time": "2023-11-09T19:14:58.289898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Important step, put model first on CPU before saving weights\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe0a93e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T19:16:43.104372Z",
     "iopub.status.busy": "2023-11-09T19:16:43.103659Z",
     "iopub.status.idle": "2023-11-09T19:16:43.157862Z",
     "shell.execute_reply": "2023-11-09T19:16:43.156979Z"
    },
    "papermill": {
     "duration": 0.371084,
     "end_time": "2023-11-09T19:16:43.159754",
     "exception": false,
     "start_time": "2023-11-09T19:16:42.788670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only saving the newly trained weights\n",
    "torch.save(dict([(k,v) for k, v in model.named_parameters() if v.requires_grad]), 'model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10627.146642,
   "end_time": "2023-11-09T19:16:52.707619",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-09T16:19:45.560977",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
